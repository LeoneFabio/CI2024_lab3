{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gem Puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque, namedtuple\n",
    "import timeit\n",
    "from random import choice\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set puzzle size \n",
    "PUZZLE_DIM = 4  \n",
    "\n",
    "# Goal State Setup\n",
    "GoalState = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "action = namedtuple('Action', ['direction', 'pos1', 'pos2'])\n",
    "\n",
    "\n",
    "# PuzzleState class that holds information about the state and search metadata\n",
    "class PuzzleState:\n",
    "    def __init__(self, state, parent=None, move=None, depth=0, cost=0, key=0):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.move = move  # Move is a string ('up', 'down', 'left', 'right')\n",
    "        self.depth = depth\n",
    "        self.cost = cost  # Number of nodes expanded so far\n",
    "        self.key = key\n",
    "        self.map = state.tobytes()\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.map == other.map\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        \"\"\"For heapq to prioritize states based on the key.\"\"\"\n",
    "        return self.key < other.key\n",
    "\n",
    "# Abstract Search Algorithm Class\n",
    "class PuzzleSearch:\n",
    "    def __init__(self, start_state):\n",
    "        self.start_state = start_state\n",
    "        self.goal_node = None\n",
    "        self.max_frontier_size = 0\n",
    "        self.max_search_depth = 0\n",
    "        self.nodes_expanded = 0\n",
    "        self.path = []\n",
    "\n",
    "    def reconstruct_path(self):\n",
    "        \"\"\"Reconstruct the solution path by tracing the parent pointers.\"\"\"\n",
    "        node = self.goal_node\n",
    "        while node and node.parent:\n",
    "            self.path.insert(0, node.move)  # Action is the string ('up', 'down', etc.)\n",
    "            node = node.parent\n",
    "\n",
    "    def get_metrics(self):\n",
    "        \"\"\"Returns the metrics for the search.\"\"\"\n",
    "        return {\n",
    "            \"quality\": len(self.path),  # Number of actions in the solution\n",
    "            \"cost\": self.nodes_expanded,  # Total nodes evaluated\n",
    "            \"efficiency\": len(self.path) / self.nodes_expanded if self.nodes_expanded > 0 else 0  # Quality vs Cost\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list:\n",
    "    \"\"\"Returns a list of possible actions (state transitions) for the current state.\"\"\"\n",
    "    x, y = np.where(state == 0)[0][0], np.where(state == 0)[1][0]\n",
    "    actions = []\n",
    "    if x > 0: actions.append(action('up', (x, y), (x - 1, y)))  # Move up\n",
    "    if x < PUZZLE_DIM - 1: actions.append(action('down', (x, y), (x + 1, y)))  # Move down\n",
    "    if y > 0: actions.append(action('left', (x, y), (x, y - 1)))  # Move left\n",
    "    if y < PUZZLE_DIM - 1: actions.append(action('right', (x, y), (x, y + 1)))  # Move right\n",
    "    return actions\n",
    "\n",
    "def do_action(state: np.ndarray, action) -> np.ndarray:\n",
    "    \"\"\"Performs an action on the given state and returns the new state.\"\"\"\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "# Heuristic for A* (Manhattan Distance)\n",
    "def manhattan_heuristic(state: np.ndarray) -> int:\n",
    "    \"\"\"Returns the Manhattan Distance heuristic for the given state.\"\"\"\n",
    "    distance = 0\n",
    "    for i in range(PUZZLE_DIM):\n",
    "        for j in range(PUZZLE_DIM):\n",
    "            value = state[i, j]\n",
    "            if value != 0:\n",
    "                target_x, target_y = divmod(value - 1, PUZZLE_DIM)\n",
    "                distance += abs(target_x - i) + abs(target_y - j)\n",
    "    return distance\n",
    "\n",
    "# Function to format the results\n",
    "def format_results(initial_state, search, metrics, execution_time):\n",
    "    # Formatting the results into a string\n",
    "    result_str = f\"\"\"\n",
    "Initial State:\n",
    "{initial_state}\n",
    "\n",
    "Path to goal: {search.path}\n",
    "Quality (path length): {metrics['quality']}\n",
    "Cost (nodes evaluated): {metrics['cost']}\n",
    "Efficiency (quality/cost): {metrics['efficiency']:.4f}\n",
    "Running time: {execution_time:.8f} seconds\n",
    "    \"\"\"\n",
    "    return result_str\n",
    "\n",
    "# Print and save the results\n",
    "def print_and_save_results(initial_state, search, metrics, execution_time):\n",
    "    # Get the formatted results\n",
    "    result_str = format_results(initial_state, search, metrics, execution_time)\n",
    "\n",
    "    # Print the results to console\n",
    "    print(result_str)\n",
    "\n",
    "    # Save the results to a file\n",
    "    with open('output.txt', 'w') as file:\n",
    "        file.write(result_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path-search algorithms\n",
    "In the follow BFS, DFS and A* algorithms are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFS(PuzzleSearch):\n",
    "    def run(self):\n",
    "        board_visited = set()\n",
    "        queue = deque([PuzzleState(self.start_state)])\n",
    "        progress = tqdm(total=1, desc=\"BFS Progress\", unit=\"node\", dynamic_ncols=True)\n",
    "\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            board_visited.add(node.map)\n",
    "            self.nodes_expanded += 1  # Increment the number of nodes expanded\n",
    "            node.cost = self.nodes_expanded  # Update the node's cost (nodes expanded)\n",
    "            progress.update(1)\n",
    "\n",
    "            if np.array_equal(node.state, GoalState):\n",
    "                progress.close()\n",
    "                self.goal_node = node\n",
    "                self.reconstruct_path()\n",
    "                return\n",
    "\n",
    "            for act in available_actions(node.state):\n",
    "                new_state = do_action(node.state, act)\n",
    "                new_node = PuzzleState(new_state, node, act.direction, node.depth + 1)  # Use action direction as move\n",
    "                if new_node.map not in board_visited:\n",
    "                    queue.append(new_node)\n",
    "                    board_visited.add(new_node.map)\n",
    "                    self.max_frontier_size = max(self.max_frontier_size, len(queue))\n",
    "                    self.max_search_depth = max(self.max_search_depth, new_node.depth)\n",
    "\n",
    "        progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFS Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFS(PuzzleSearch):\n",
    "    def run(self):\n",
    "        board_visited = set()\n",
    "        stack = [PuzzleState(self.start_state)]\n",
    "        progress = tqdm(total=1, desc=\"DFS Progress\", unit=\"node\", dynamic_ncols=True)\n",
    "\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "            board_visited.add(node.map)\n",
    "            self.nodes_expanded += 1  # Increment the number of nodes expanded\n",
    "            node.cost = self.nodes_expanded  # Update the node's cost (nodes expanded)\n",
    "            progress.update(1)\n",
    "\n",
    "            if np.array_equal(node.state, GoalState):\n",
    "                progress.close()\n",
    "                self.goal_node = node\n",
    "                self.reconstruct_path()\n",
    "                return\n",
    "\n",
    "            for act in reversed(available_actions(node.state)):\n",
    "                new_state = do_action(node.state, act)\n",
    "                new_node = PuzzleState(new_state, node, act.direction, node.depth + 1)  # Use action direction as move\n",
    "                if new_node.map not in board_visited:\n",
    "                    stack.append(new_node)\n",
    "                    board_visited.add(new_node.map)\n",
    "                    self.max_frontier_size = max(self.max_frontier_size, len(stack))\n",
    "                    self.max_search_depth = max(self.max_search_depth, new_node.depth)\n",
    "\n",
    "        progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A* Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AStar(PuzzleSearch):\n",
    "    def run(self):\n",
    "        board_visited = set()\n",
    "        initial_key = manhattan_heuristic(self.start_state)\n",
    "        queue = [PuzzleState(self.start_state, key=initial_key)]\n",
    "        heapq.heapify(queue)\n",
    "        progress = tqdm(total=1, desc=\"A* Progress\", unit=\"node\", dynamic_ncols=True)\n",
    "\n",
    "        while queue:\n",
    "            node = heapq.heappop(queue)\n",
    "            self.nodes_expanded += 1  # Increment the number of nodes expanded\n",
    "            node.cost = self.nodes_expanded  # Update the node's cost (nodes expanded)\n",
    "            progress.update(1)\n",
    "\n",
    "            if np.array_equal(node.state, GoalState):\n",
    "                progress.close()\n",
    "                self.goal_node = node\n",
    "                self.reconstruct_path()\n",
    "                return\n",
    "\n",
    "            for act in available_actions(node.state):\n",
    "                new_state = do_action(node.state, act)\n",
    "                new_node = PuzzleState(new_state, node, act.direction, node.depth + 1)  # Use action direction as move\n",
    "                if new_node.map not in board_visited:\n",
    "                    new_node.key = manhattan_heuristic(new_state) + new_node.depth\n",
    "                    heapq.heappush(queue, new_node)\n",
    "                    board_visited.add(new_node.map)\n",
    "                    self.max_frontier_size = max(self.max_frontier_size, len(queue))\n",
    "                    self.max_search_depth = max(self.max_search_depth, new_node.depth)\n",
    "\n",
    "        progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the specified path-search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 100/100 [00:00<00:00, 184771.10it/s]\n",
      "A* Progress: 1597node [00:00, 14884.16node/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial State:\n",
      "[[ 1  3 12  4]\n",
      " [ 5  0  6  8]\n",
      " [ 2 11  7 15]\n",
      " [13  9 10 14]]\n",
      "\n",
      "Path to goal: ['right', 'up', 'right', 'down', 'left', 'down', 'left', 'left', 'up', 'right', 'down', 'down', 'right', 'right', 'up', 'up', 'up', 'left', 'left', 'down', 'left', 'down', 'right', 'down', 'right', 'right']\n",
      "Quality (path length): 26\n",
      "Cost (nodes evaluated): 1597\n",
      "Efficiency (quality/cost): 0.0163\n",
      "Running time: 0.11565870 seconds\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Choose search method\n",
    "search_method = \"astar\"  # Choose from \"bfs\", \"dfs\", or \"astar\"\n",
    "\n",
    "\n",
    "# Create scrambled initial state\n",
    "initial_state = GoalState.copy()\n",
    "randomize_steps = 100  # Number of random moves to scramble\n",
    "for _ in tqdm(range(randomize_steps), desc=\"Randomizing\"):\n",
    "    initial_state = do_action(initial_state, choice(available_actions(initial_state)))\n",
    "\n",
    "search = None\n",
    "\n",
    "if search_method == \"bfs\":\n",
    "    search = BFS(initial_state)\n",
    "elif search_method == \"dfs\":\n",
    "    search = DFS(initial_state)\n",
    "elif search_method == \"astar\":\n",
    "    search = AStar(initial_state)\n",
    "\n",
    "# Run the search and time it\n",
    "start = timeit.default_timer()\n",
    "search.run()\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "# Calculate execution time\n",
    "execution_time = stop - start\n",
    "\n",
    "# Get metrics\n",
    "metrics = search.get_metrics()\n",
    "\n",
    "# Print and save the results\n",
    "print_and_save_results(initial_state, search, metrics, execution_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
